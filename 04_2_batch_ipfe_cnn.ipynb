{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "c2760c72956b3d3"
  },
  {
   "cell_type": "code",
   "id": "c29d01d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:48:59.409292Z",
     "start_time": "2025-11-13T13:48:52.882501Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from cryptography.optimized_cnn_ipfe import IPFE, decrypt_patches_batch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:48:59.656849Z",
     "start_time": "2025-11-13T13:48:59.651971Z"
    }
   },
   "cell_type": "code",
   "id": "81bbf67e",
   "source": [
    "base_model = 1\n",
    "model_path = f\"models/cnn_model_{base_model}.pth\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Model",
   "id": "27fbee36ace173f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:48:59.692076Z",
     "start_time": "2025-11-13T13:48:59.672573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class IPFECNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, prime=4590007):\n",
    "        super(IPFECNN, self).__init__()\n",
    "        self.prime = prime\n",
    "        self.ipfe = IPFE(prime)\n",
    "        self.encryption_length = 9 # 3x3 filter size flattened\n",
    "\n",
    "        self.ipfe.setup(self.encryption_length)\n",
    "        print(\"IPFE setup done, with length:\", self.encryption_length)\n",
    "\n",
    "        # First convolutional block - this will be used with IPFE\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1) # stride = 2, padding = 0\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 128) # 64 * 1 * 1, 128\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "        #copy weights from the trained model\n",
    "        self.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        print(\"weights copied from trained model\")\n",
    "\n",
    "        self.weights = self.conv1.weight.data\n",
    "        self.y_array = torch.round(self.weights.view(self.weights.size(0), -1).squeeze(1).view(self.weights.size(0), -1) * 10000).long().tolist()\n",
    "        print(\"weights converted to y vectors\")\n",
    "        self.biases = self.conv1.bias\n",
    "        print(\"biases saved\")\n",
    "        self.sk_y_array = [self.ipfe.key_derive(y) for y in self.y_array]\n",
    "        print(\"sk_ys created\")\n",
    "\n",
    "    def encrypt_data(self, test_set):\n",
    "        unfold = nn.Unfold(kernel_size=3, stride=1, padding=1)\n",
    "        patches = unfold(test_set)\n",
    "        B, patch_size, num_patches = patches.shape\n",
    "\n",
    "        encrypted_batch= []\n",
    "\n",
    "        for b in range(B):\n",
    "            patches_b = patches[b].T  # (H*W, patch_size)\n",
    "            ct0_array = np.zeros(num_patches, dtype=np.int64)\n",
    "            cts_array = np.zeros((num_patches, patch_size), dtype=np.int64)\n",
    "\n",
    "            for p_idx in range(num_patches):\n",
    "                patch = patches_b[p_idx]\n",
    "                patch_int = np.array([int(val.item()) % (self.prime - 1) for val in patch], dtype=np.int64)\n",
    "                ct0, ct = self.ipfe.encrypt(patch_int)\n",
    "\n",
    "                ct0_array[p_idx] = ct0\n",
    "                cts_array[p_idx, :] = np.array(ct, dtype=np.int64)\n",
    "\n",
    "            encrypted_batch.append((ct0_array, cts_array))\n",
    "\n",
    "        return encrypted_batch\n",
    "\n",
    "    def first_conv_forward(self, encrypted_image, H, W):\n",
    "        num_kernels = len(self.sk_y_array)\n",
    "        device = next(self.parameters()).device\n",
    "        ct0_array, cts_array = encrypted_image\n",
    "        num_patches = ct0_array.shape[0]\n",
    "\n",
    "        decrypted_maps = torch.zeros(num_kernels, num_patches, device=device)\n",
    "\n",
    "        # Loop over kernels\n",
    "        for k in range(num_kernels):\n",
    "            sk_y = int(self.sk_y_array[k])\n",
    "            y_vec = np.array(self.y_array[k], dtype=np.int64)\n",
    "            bias = float(self.biases[k].item())\n",
    "\n",
    "            # Batch decrypt all patches using Numba\n",
    "            decrypted_vals = decrypt_patches_batch(ct0_array, cts_array, sk_y, y_vec, self.ipfe.g, self.prime)\n",
    "\n",
    "            # Scale and add bias\n",
    "            decrypted_maps[k, :] = torch.tensor(decrypted_vals / 10000.0 + bias, device=device)\n",
    "\n",
    "        # Reshape to (1, num_kernels, H, W)\n",
    "        return decrypted_maps.view(1, num_kernels, H, W)\n",
    "\n",
    "    def forward(self, x, H, W, encrypted=False):\n",
    "        if encrypted:\n",
    "            outputs = []\n",
    "            for sample in x:  # x = [ [patches_img1], [patches_img2], ... ]\n",
    "                feat = self.first_conv_forward(sample, H, W)\n",
    "                feat = self.pool1(F.relu(self.bn1(feat)))\n",
    "                feat = self.pool2(F.relu(self.bn2(self.conv2(feat))))\n",
    "                feat = self.pool3(F.relu(self.bn3(self.conv3(feat))))\n",
    "                feat = feat.view(feat.size(0), -1)\n",
    "                feat = F.relu(self.fc1(feat))\n",
    "                feat = self.dropout(feat)\n",
    "                feat = self.fc2(feat)\n",
    "                outputs.append(feat)\n",
    "            return torch.cat(outputs, dim=0)\n",
    "        else:\n",
    "            x = self.conv1(x)\n",
    "            x = self.pool1(F.relu(self.bn1(x)))\n",
    "            x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "            x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n"
   ],
   "id": "1676e5f31cb13236",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Data",
   "id": "5b0c361d9e08bdc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:49:02.108424Z",
     "start_time": "2025-11-13T13:49:02.086599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda pic: torch.tensor(np.array(pic), dtype=torch.float32).unsqueeze(0))\n",
    "])\n",
    "batch_size = 64\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ],
   "id": "a6ca222b126041b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 10000\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize Model",
   "id": "115693bf5af5c6e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:49:05.044680Z",
     "start_time": "2025-11-13T13:49:05.019196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize IPFE-enhanced CNN\n",
    "# bei n=5\n",
    "\n",
    "# mit kernel 3x3, stride 1, padding 1\n",
    "# 1721257 mit 16 373ms scheint sicher zu sein\n",
    "# 2300003 mit 21 721ms sollte sehr wahrscheinlich sicher zu sein\n",
    "# 4590007 mit 29 470ms muss mathematisch sicher sein\n",
    "\n",
    "# mit kernel 3x3, stride 2, padding 0\n",
    "# 1721257 nur 60%\n",
    "# 2300003 nur 80%\n",
    "# 4590007 mit 5 708ms\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ipfe_model = IPFECNN(num_classes=10, prime=4590007).to(device)\n",
    "\n",
    "print(f\"IPFE-CNN model created on device: {device}\")"
   ],
   "id": "3475215f0449f362",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPFE setup done, with length: 9\n",
      "weights copied from trained model\n",
      "weights converted to y vectors\n",
      "biases saved\n",
      "sk_ys created\n",
      "IPFE-CNN model created on device: cpu\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:49:05.078374Z",
     "start_time": "2025-11-13T13:49:05.068861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encrypt_test_data(model, test_loader, device, num_samples=5):\n",
    "    \"\"\"Encrypt a batch of test data\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Get a batch of test data\n",
    "        data_iter = iter(test_loader)\n",
    "        images, labels = next(data_iter)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Encrypt only a subset\n",
    "        images_subset = images[:num_samples]\n",
    "        labels_subset = labels[:num_samples]\n",
    "\n",
    "        # Encrypt the data\n",
    "        encrypted_data = model.encrypt_data(images_subset)\n",
    "        print(f\"Encrypted {num_samples} samples.\")\n",
    "\n",
    "        H, W = images.size(2), images.size(3)\n",
    "\n",
    "    return encrypted_data, labels_subset, H, W"
   ],
   "id": "f7b0413ef3a19de4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:49:05.507082Z",
     "start_time": "2025-11-13T13:49:05.104941Z"
    }
   },
   "cell_type": "code",
   "source": "encrypted_data, labels, H, W = encrypt_test_data(ipfe_model, test_loader, device, num_samples=5)",
   "id": "743adafe19e1c144",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encrypted 5 samples.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test model",
   "id": "5da34a2e844625c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:49:08.480805Z",
     "start_time": "2025-11-13T13:49:08.471381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test IPFE functionality with a sample\n",
    "def test_ipfe_cnn(model, encrypted_data, labels, H, W, device):\n",
    "    \"\"\"Test the IPFE-CNN with a sample query vector\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"Testing IPFE-CNN forward pass on encrypted data...\")\n",
    "        print(f\"Labels of test samples: {labels.cpu().numpy()}\")\n",
    "\n",
    "        try:\n",
    "            outputs = model.forward(encrypted_data, encrypted=True, H=28, W=28) # 13 13\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            print(f\"Predictions on encrypted data: {predicted.cpu().numpy()}\")\n",
    "\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            total = labels.size(0)\n",
    "            print(f\"Accuracy on encrypted samples: {100 * correct / total:.2f}% ({correct}/{total})\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Encrypted IPFE forward pass failed: {e}\")\n"
   ],
   "id": "d06bc5ba89e5cfa6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:49:08.508443Z",
     "start_time": "2025-11-13T13:49:08.500771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_regular_ipfe_cnn(model, test_loader, device, num_samples=5):\n",
    "    \"\"\"Test the IPFE-CNN with a sample query vector\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"Testing IPFE-CNN forward pass on encrypted data...\")\n",
    "\n",
    "        data_iter = iter(test_loader)\n",
    "        images, labels = next(data_iter)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Encrypt only a subset\n",
    "        images_subset = images[:num_samples]\n",
    "        labels_subset = labels[:num_samples]\n",
    "        try:\n",
    "            outputs = model.forward(images_subset, encrypted=False, H=28, W=26) # 13 13\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            print(f\"Predictions on encrypted data: {predicted.cpu().numpy()}\")\n",
    "\n",
    "            correct = (predicted == labels_subset).sum().item()\n",
    "            total = labels_subset.size(0)\n",
    "            print(f\"Accuracy on encrypted samples: {100 * correct / total:.2f}% ({correct}/{total})\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Encrypted IPFE forward pass failed: {e}\")"
   ],
   "id": "e83789450ba19902",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:49:20.371105Z",
     "start_time": "2025-11-13T13:49:08.535103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Testing IPFE-CNN functionality...\")\n",
    "test_ipfe_cnn(ipfe_model, encrypted_data, labels, H, W, device)\n"
   ],
   "id": "7c27e8d3d7435993",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing IPFE-CNN functionality...\n",
      "Testing IPFE-CNN forward pass on encrypted data...\n",
      "Labels of test samples: [7 2 1 0 4]\n",
      "Predictions on encrypted data: [7 2 1 0 4]\n",
      "Accuracy on encrypted samples: 100.00% (5/5)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:49:20.416438Z",
     "start_time": "2025-11-13T13:49:20.395616Z"
    }
   },
   "cell_type": "code",
   "source": "test_regular_ipfe_cnn(ipfe_model, test_loader, device, num_samples=5)",
   "id": "af638cf14768fc43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing IPFE-CNN forward pass on encrypted data...\n",
      "Predictions on encrypted data: [7 2 1 0 4]\n",
      "Accuracy on encrypted samples: 100.00% (5/5)\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
