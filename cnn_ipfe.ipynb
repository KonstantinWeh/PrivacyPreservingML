{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:57:43.870382Z",
     "start_time": "2025-10-14T17:57:43.866006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "444f21327213e4fe",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:57:45.016142Z",
     "start_time": "2025-10-14T17:57:45.011850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST"
   ],
   "id": "92f2fe85ca516d0",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Trained CNN on MNIST",
   "id": "2c59d09ff13d86b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T18:00:42.345146Z",
     "start_time": "2025-10-14T17:58:32.418912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a lightweight CNN architecture\n",
    "class LightweightCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LightweightCNN, self).__init__()\n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 128)  # 28x28 -> 14x14 -> 7x7 -> 3x3 after pooling\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First conv block\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "\n",
    "        # Second conv block\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "\n",
    "        # Third conv block\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "\n",
    "        # Flatten and fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LightweightCNN(num_classes=10).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Model created on device: {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, device, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "            if batch_idx % 200 == 0:\n",
    "                print(f'Epoch {epoch + 1}/{epochs}, Batch {batch_idx}/{len(train_loader)}, '\n",
    "                      f'Loss: {loss.item():.4f}, Accuracy: {100. * correct / total:.2f}%')\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        print(f'Epoch {epoch + 1} completed - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "        print('-' * 50)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "train_model(model, train_loader, criterion, optimizer, device, epochs=3)\n",
    "\n",
    "\n",
    "# Test the model\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Evaluate the trained model\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_accuracy = test_model(model, test_loader, device)\n",
    "\n",
    "\n",
    "# Visualize some predictions\n",
    "def visualize_predictions(model, test_loader, device, num_samples=8):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of test data\n",
    "        data_iter = iter(test_loader)\n",
    "        images, labels = next(data_iter)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Get predictions\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        # Move back to CPU for visualization\n",
    "        images = images.cpu()\n",
    "        labels = labels.cpu()\n",
    "        predicted = predicted.cpu()\n",
    "\n",
    "        # Create subplot\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "        axes = axes.ravel()\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            axes[i].imshow(images[i].squeeze(), cmap='gray')\n",
    "            axes[i].set_title(f'True: {labels[i].item()}, Pred: {predicted[i].item()}')\n",
    "            axes[i].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Visualize predictions\n",
    "print(\"Visualizing some predictions...\")\n",
    "visualize_predictions(model, test_loader, device)\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST normalization\n",
    "])\n",
    "\n",
    "# Load training and test datasets\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7a0076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ipfe functions\n",
    "from ip_functional_encryption import setup, encrypt, key_der, decrypt, FunctionalEncryptionDemo"
   ],
   "id": "d267709c6289289e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:57:49.123351Z",
     "start_time": "2025-10-14T17:57:49.106593Z"
    }
   },
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1b915ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IPFE-enhanced CNN with functional encryption\n",
    "class IPFECNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, prime=104729):\n",
    "        super(IPFECNN, self).__init__()\n",
    "        self.prime = prime\n",
    "        \n",
    "        # First convolutional block - this will be used with IPFE\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        # IPFE setup for first conv layer\n",
    "        self.ipfe_setup_done = False\n",
    "        self.mpk = None\n",
    "        self.msk = None\n",
    "        \n",
    "    def setup_ipfe(self):\n",
    "        \"\"\"Setup IPFE for the first convolutional layer\"\"\"\n",
    "        # Get the first conv layer weights and flatten them\n",
    "        conv1_weights = self.conv1.weight.data.cpu().numpy()\n",
    "        # Flatten weights: [out_channels, in_channels, height, width] -> [out_channels * in_channels * height * width]\n",
    "        self.conv1_weights_flat = conv1_weights.flatten()\n",
    "        self.conv1_length = len(self.conv1_weights_flat)\n",
    "        \n",
    "        # Convert to integers for IPFE (scale and round)\n",
    "        self.conv1_weights_int = [int(w * 1000) % (self.prime - 1) for w in self.conv1_weights_flat]\n",
    "        \n",
    "        # Setup IPFE\n",
    "        self.mpk, self.msk = setup(self.conv1_length, self.prime)\n",
    "        self.ipfe_setup_done = True\n",
    "        print(f\"IPFE setup complete for conv1 layer with {self.conv1_length} parameters\")\n",
    "        \n",
    "    def forward_with_ipfe(self, x, y_vector=None):\n",
    "        \"\"\"Forward pass with IPFE for the first convolutional layer\"\"\"\n",
    "        if not self.ipfe_setup_done:\n",
    "            self.setup_ipfe()\n",
    "            \n",
    "        # If y_vector is provided, use IPFE for first conv\n",
    "        if y_vector is not None:\n",
    "            # Encrypt the input x (flattened)\n",
    "            x_flat = x.view(x.size(0), -1).cpu().numpy()\n",
    "            \n",
    "            # For each sample in the batch, compute IPFE\n",
    "            ipfe_results = []\n",
    "            for i in range(x.size(0)):\n",
    "                # Convert input to integers\n",
    "                x_int = [int(val * 1000) % (self.prime - 1) for val in x_flat[i]]\n",
    "                \n",
    "                # Encrypt input\n",
    "                ct = encrypt(self.mpk, x_int)\n",
    "                \n",
    "                # Derive key for y_vector\n",
    "                sk_y = key_der(self.msk, y_vector, self.prime)\n",
    "                \n",
    "                # Decrypt to get inner product\n",
    "                try:\n",
    "                    inner_product = decrypt(self.mpk, ct, sk_y, y_vector)\n",
    "                    ipfe_results.append(inner_product)\n",
    "                except:\n",
    "                    # Fallback to regular computation if IPFE fails\n",
    "                    inner_product = sum(xi * yi for xi, yi in zip(x_int, y_vector)) % (self.prime - 1)\n",
    "                    ipfe_results.append(inner_product)\n",
    "            \n",
    "            # Convert IPFE results back to tensor\n",
    "            ipfe_tensor = torch.tensor(ipfe_results, dtype=torch.float32).to(x.device)\n",
    "            \n",
    "            # Use regular conv for remaining layers\n",
    "            x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        else:\n",
    "            # Regular forward pass\n",
    "            x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        \n",
    "        # Continue with remaining layers\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Flatten and fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Regular forward pass without IPFE\"\"\"\n",
    "        # First conv block\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        \n",
    "        # Second conv block\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        # Third conv block\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Flatten and fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ],
   "id": "fab41d88b1055a93",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:57:52.938187Z",
     "start_time": "2025-10-14T17:57:52.900573Z"
    }
   },
   "cell_type": "code",
   "execution_count": 34,
   "id": "f05c5ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPFE-CNN model created on device: cpu\n",
      "Total parameters: 98,666\n",
      "IPFE setup complete for conv1 layer with 144 parameters\n"
     ]
    }
   ],
   "source": [
    "# Initialize IPFE-enhanced CNN\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ipfe_model = IPFECNN(num_classes=10, prime=104729).to(device)\n",
    "\n",
    "# Copy weights from the trained model\n",
    "ipfe_model.load_state_dict(model.state_dict())\n",
    "\n",
    "print(f\"IPFE-CNN model created on device: {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in ipfe_model.parameters()):,}\")\n",
    "\n",
    "# Setup IPFE for the first convolutional layer\n",
    "ipfe_model.setup_ipfe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "968c6276",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      3\u001B[39m ipfe_model = IPFECNN(num_classes=\u001B[32m10\u001B[39m, prime=\u001B[32m104729\u001B[39m).to(device)\n\u001B[32m      5\u001B[39m \u001B[38;5;66;03m# Copy weights from the trained model\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m ipfe_model.load_state_dict(\u001B[43mmodel\u001B[49m.state_dict())\n\u001B[32m      8\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mIPFE-CNN model created on device: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m      9\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTotal parameters: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28msum\u001B[39m(p.numel()\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mp\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mipfe_model.parameters())\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m,\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:38:00.520216Z",
     "start_time": "2025-10-14T17:38:00.486080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test IPFE functionality with a sample\n",
    "def test_ipfe_cnn(model, test_loader, device, num_samples=5):\n",
    "    \"\"\"Test the IPFE-CNN with a sample query vector\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Create a sample query vector y (same length as flattened conv1 weights)\n",
    "    y_vector = [1] * model.conv1_length  # Simple query vector of all 1s\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get a batch of test data\n",
    "        data_iter = iter(test_loader)\n",
    "        images, labels = next(data_iter)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Test regular forward pass\n",
    "        print(\"Testing regular forward pass...\")\n",
    "        regular_outputs = model(images[:num_samples])\n",
    "        _, regular_predicted = regular_outputs.max(1)\n",
    "        \n",
    "        # Test IPFE forward pass\n",
    "        print(\"Testing IPFE forward pass...\")\n",
    "        try:\n",
    "            ipfe_outputs = model.forward_with_ipfe(images[:num_samples], y_vector)\n",
    "            _, ipfe_predicted = ipfe_outputs.max(1)\n",
    "            \n",
    "            print(f\"Regular predictions: {regular_predicted.cpu().numpy()}\")\n",
    "            print(f\"IPFE predictions: {ipfe_predicted.cpu().numpy()}\")\n",
    "            print(f\"True labels: {labels[:num_samples].cpu().numpy()}\")\n",
    "            \n",
    "            # Compare results\n",
    "            matches = (regular_predicted == ipfe_predicted).sum().item()\n",
    "            print(f\"Prediction matches between regular and IPFE: {matches}/{num_samples}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"IPFE forward pass failed: {e}\")\n",
    "            print(\"This is expected for large vectors due to computational limitations\")\n",
    "\n",
    "# Test the IPFE functionality\n",
    "print(\"Testing IPFE-CNN functionality...\")\n",
    "test_ipfe_cnn(ipfe_model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4356635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing IPFE-CNN functionality...\n",
      "Testing regular forward pass...\n",
      "Testing IPFE forward pass...\n",
      "IPFE forward pass failed: name 'p' is not defined\n",
      "This is expected for large vectors due to computational limitations\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Demonstrate IPFE with different query vectors\n",
    "def demonstrate_ipfe_queries(model, test_loader, device):\n",
    "    \"\"\"Demonstrate IPFE with different query vectors\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a single test sample\n",
    "    data_iter = iter(test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    single_image = images[0:1].to(device)  # Single sample\n",
    "    true_label = labels[0].item()\n",
    "    \n",
    "    print(f\"Testing with image of digit: {true_label}\")\n",
    "    \n",
    "    # Different query vectors to test\n",
    "    query_vectors = {\n",
    "        \"All ones\": [1] * model.conv1_length,\n",
    "        \"All zeros\": [0] * model.conv1_length,\n",
    "        \"Alternating\": [1 if i % 2 == 0 else -1 for i in range(model.conv1_length)],\n",
    "        \"Random\": [1, 0, 1, 0] * (model.conv1_length // 4) + [1] * (model.conv1_length % 4)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nTesting different query vectors:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for name, y_vector in query_vectors.items():\n",
    "        try:\n",
    "            # Regular forward pass\n",
    "            regular_output = model(single_image)\n",
    "            regular_pred = regular_output.max(1)[1].item()\n",
    "            \n",
    "            # IPFE forward pass\n",
    "            ipfe_output = model.forward_with_ipfe(single_image, y_vector)\n",
    "            ipfe_pred = ipfe_output.max(1)[1].item()\n",
    "            \n",
    "            print(f\"{name:15} - Regular: {regular_pred}, IPFE: {ipfe_pred}, Match: {regular_pred == ipfe_pred}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{name:15} - IPFE failed: {str(e)[:50]}...\")\n",
    "\n",
    "# Demonstrate with different queries\n",
    "print(\"Demonstrating IPFE with different query vectors...\")\n",
    "demonstrate_ipfe_queries(ipfe_model, test_loader, device)\n"
   ],
   "id": "7c6b5af57aa8adbb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 37,
   "id": "87803409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing first CNN layer filters...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the first CNN layer's filters (weights)\n",
    "def visualize_first_cnn_layer(model):\n",
    "    \"\"\"Visualize the first convolutional layer filters\"\"\"\n",
    "    # Find the first conv layer\n",
    "    first_conv = None\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, torch.nn.Conv2d):\n",
    "            first_conv = m\n",
    "            break\n",
    "    if first_conv is None:\n",
    "        print(\"No Conv2d layer found in model.\")\n",
    "        return\n",
    "\n",
    "    weights = first_conv.weight.data.cpu()\n",
    "    num_filters = weights.shape[0]\n",
    "\n",
    "    # Calculate grid size\n",
    "    cols = 8\n",
    "    rows = (num_filters + cols - 1) // cols\n",
    "\n",
    "    plt.figure(figsize=(cols*1.5, rows*1.5))\n",
    "    for i in range(num_filters):\n",
    "        ax = plt.subplot(rows, cols, i+1)\n",
    "        # For grayscale, show as [out_ch, in_ch, H, W]\n",
    "        w = weights[i, 0].numpy()\n",
    "        ax.imshow(w, cmap='gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'F{i}')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"First Conv Layer Filters (IPFE-enhanced)\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualizing first CNN layer filters...\")\n",
    "visualize_first_cnn_layer(ipfe_model)\n"
   ],
   "id": "f216c67c637d3a70"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "id": "2fcaa144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc540511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d2276a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
