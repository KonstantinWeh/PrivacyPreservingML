{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "c2760c72956b3d3"
  },
  {
   "cell_type": "code",
   "id": "c29d01d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:30:52.214664Z",
     "start_time": "2025-10-19T21:30:51.454958Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fontTools.misc.eexec import encrypt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "81bbf67e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:30:57.137313Z",
     "start_time": "2025-10-19T21:30:52.474871Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Trained CNN",
   "id": "ca69fe0bf0214053"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:30:57.158463Z",
     "start_time": "2025-10-19T21:30:57.152191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ToTensor255:\n",
    "    def __call__(self, pic):\n",
    "        # Convert PIL image to a torch tensor (H x W)\n",
    "        return torch.tensor(np.array(pic), dtype=torch.float32)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    ToTensor255()\n",
    "])\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.1307,), (0.3081,))\n",
    "# ])\n"
   ],
   "id": "7bc83462e46a7913",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:30:59.588715Z",
     "start_time": "2025-10-19T21:30:59.530257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load training and test datasets\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ],
   "id": "ec44f3165f628cc6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "8f8ff355",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:31:00.916140Z",
     "start_time": "2025-10-19T21:31:00.908651Z"
    }
   },
   "source": [
    "# Define a lightweight CNN architecture\n",
    "class LightweightCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LightweightCNN, self).__init__()\n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 128)  # 28x28 -> 14x14 -> 7x7 -> 3x3 after pooling\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # First conv block\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        \n",
    "        # Second conv block\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        # Third conv block\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Flatten and fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "fb3f84ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:31:03.148557Z",
     "start_time": "2025-10-19T21:31:03.136003Z"
    }
   },
   "source": [
    "# Initialize the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LightweightCNN(num_classes=10).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Model created on device: {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created on device: cpu\n",
      "Total parameters: 98,666\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "fe24be06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:31:05.535869Z",
     "start_time": "2025-10-19T21:31:04.783784Z"
    }
   },
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, device, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "            \n",
    "            if batch_idx % 200 == 0:\n",
    "                print(f'Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(train_loader)}, '\n",
    "                      f'Loss: {loss.item():.4f}, Accuracy: {100.*correct/total:.2f}%')\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        print(f'Epoch {epoch+1} completed - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "        print('-' * 50)\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "train_model(model, train_loader, criterion, optimizer, device, epochs=3)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 1, 3, 3], expected input[1, 64, 28, 28] to have 1 channels, but got 64 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 34\u001B[39m\n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[32m     33\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mStarting training...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m34\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 13\u001B[39m, in \u001B[36mtrain_model\u001B[39m\u001B[34m(model, train_loader, criterion, optimizer, device, epochs)\u001B[39m\n\u001B[32m     10\u001B[39m data, target = data.to(device), target.to(device)\n\u001B[32m     12\u001B[39m optimizer.zero_grad()\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m output = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     14\u001B[39m loss = criterion(output, target)\n\u001B[32m     15\u001B[39m loss.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mG:\\Projects\\PrivacyPreservingML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mG:\\Projects\\PrivacyPreservingML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 27\u001B[39m, in \u001B[36mLightweightCNN.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m     26\u001B[39m     \u001B[38;5;66;03m# First conv block\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.pool1(F.relu(\u001B[38;5;28mself\u001B[39m.bn1(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)))\n\u001B[32m     29\u001B[39m     \u001B[38;5;66;03m# Second conv block\u001B[39;00m\n\u001B[32m     30\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.pool2(F.relu(\u001B[38;5;28mself\u001B[39m.bn2(\u001B[38;5;28mself\u001B[39m.conv2(x))))\n",
      "\u001B[36mFile \u001B[39m\u001B[32mG:\\Projects\\PrivacyPreservingML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mG:\\Projects\\PrivacyPreservingML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mG:\\Projects\\PrivacyPreservingML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001B[39m, in \u001B[36mConv2d.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    547\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m548\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mG:\\Projects\\PrivacyPreservingML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:543\u001B[39m, in \u001B[36mConv2d._conv_forward\u001B[39m\u001B[34m(self, input, weight, bias)\u001B[39m\n\u001B[32m    531\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.padding_mode != \u001B[33m\"\u001B[39m\u001B[33mzeros\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    532\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m F.conv2d(\n\u001B[32m    533\u001B[39m         F.pad(\n\u001B[32m    534\u001B[39m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m._reversed_padding_repeated_twice, mode=\u001B[38;5;28mself\u001B[39m.padding_mode\n\u001B[32m   (...)\u001B[39m\u001B[32m    541\u001B[39m         \u001B[38;5;28mself\u001B[39m.groups,\n\u001B[32m    542\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m543\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    544\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgroups\u001B[49m\n\u001B[32m    545\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: Given groups=1, weight of size [16, 1, 3, 3], expected input[1, 64, 28, 28] to have 1 channels, but got 64 channels instead"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "3ec1ed97",
   "metadata": {},
   "source": [
    "# Test the model\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the trained model\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_accuracy = test_model(model, test_loader, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d66e75db",
   "metadata": {},
   "source": [
    "# Visualize some predictions\n",
    "def visualize_predictions(model, test_loader, device, num_samples=8):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of test data\n",
    "        data_iter = iter(test_loader)\n",
    "        images, labels = next(data_iter)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        \n",
    "        # Move back to CPU for visualization\n",
    "        images = images.cpu()\n",
    "        labels = labels.cpu()\n",
    "        predicted = predicted.cpu()\n",
    "        \n",
    "        # Create subplot\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "        axes = axes.ravel()\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            axes[i].imshow(images[i].squeeze(), cmap='gray')\n",
    "            axes[i].set_title(f'True: {labels[i].item()}, Pred: {predicted[i].item()}')\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Visualize predictions\n",
    "print(\"Visualizing some predictions...\")\n",
    "visualize_predictions(model, test_loader, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a670e23b",
   "metadata": {},
   "source": "## IPFE-enhanced CNN"
  },
  {
   "cell_type": "code",
   "id": "e7a0076c",
   "metadata": {},
   "source": [
    "# import ipfe functions\n",
    "from ip_functional_encryption import IPFE"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### current try",
   "id": "a0e9809d3ef7052c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In the First layer we applied 16 filters of size 3x3, with input channel 1 (grayscale), so the total number of parameters is 16 * 3 * 3 * 1 = 144.\n",
    "\n",
    "So With that each y is one filter flattened to a vector of length 9.\n",
    "For an input x of size 28x28, flattened to a vector of length 784, we can compute the inner product <x, y> for each filter y.\n",
    "\n",
    "Option 1 encrypt the entire input x of length 784, and padd the y to a length of 784 with zeros. -> This will be inefficient as the IPFE scheme will have to handle large vectors.\n",
    "\n",
    "Option 2 encrypt patches of x corresponding to the filter size (3x3 = 9 elements), and compute the inner product for each patch with the filter y. This requires sliding the filter over the input image and encrypting each patch separately.\n",
    "\n",
    "1. Step: Create patches of size 3x3 from the input image (28x28) -> This will create 28x28 patches (with padding). => 784 patches\n",
    "2. Step: Encrypt each patch separately.\n",
    "3. Step: Create 16 query vectors y (one for each filter), each of size 9 (3x3 flattened). => Create a Key for each vector\n",
    "4. Step: decrypt each inner product result to get the convolution output."
   ],
   "id": "e412789862c18ee8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class IPFECNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, prime=104729):\n",
    "        super(IPFECNN, self).__init__()\n",
    "        self.prime = prime\n",
    "        self.ipfe = IPFE(prime)\n",
    "        self.encryption_length = 9 # 3x3 filter size flattened\n",
    "\n",
    "        self.ipfe.setup(self.encryption_length)\n",
    "        print(\"IPFE setup done, with length:\", self.encryption_length)\n",
    "\n",
    "        # First convolutional block - this will be used with IPFE\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "        #copy weights from the trained model\n",
    "        self.load_state_dict(model.state_dict())\n",
    "        print(\"weights copied from trained model\")\n",
    "\n",
    "        self.y_array = self.conv1.weight.data.view(self.conv1.weight.data.size(0), -1).squeeze(1).view(self.conv1.weight.data.size(0), -1)\n",
    "        print(\"weights converted to y vectors\")\n",
    "        self.sk_y_array = torch.tensor([self.ipfe.key_derive(y) for y in self.y_array])\n",
    "        print(\"sk_ys created\")\n",
    "        # convert y to int here\n",
    "\n",
    "\n",
    "    def forward(self, x, encrypted=False):\n",
    "        # If y_vector is provided, use IPFE for first conv\n",
    "        if encrypted:\n",
    "            print(\"x shape:\", x.shape)\n",
    "\n",
    "            batch_size = x.shape[0]\n",
    "            H, W = x.shape[2], x.shape[3]\n",
    "\n",
    "            unfold = nn.Unfold(kernel_size=3, stride=1, padding=1)\n",
    "            patches = unfold(x)\n",
    "            num_patches = patches.shape[-1]\n",
    "            num_kernels = len(self.sk_y_array)\n",
    "\n",
    "            feature_maps_batch = []\n",
    "\n",
    "            for b in range(batch_size):\n",
    "                patches_b = patches[b].T\n",
    "                decrypted_maps = torch.zeros(num_kernels, num_patches, device=x.device)\n",
    "\n",
    "                # Loop over patches and kernels\n",
    "                for p in range(num_patches):\n",
    "                    patch = patches_b[p]\n",
    "                    patch_int = [(int(val.item() * 1000) % (self.prime - 1)) for val in patch]\n",
    "\n",
    "                    for k in range(num_kernels):\n",
    "                        sk_y = int((self.sk_y_array)[k])  # scalar\n",
    "                        y_val = [int(val) for val in self.y_array[k]]   # (9,)\n",
    "\n",
    "                        encrypted = self.ipfe.encrypt(patch_int)\n",
    "                        decrypted = self.ipfe.decrypt(encrypted, sk_y, y_val)\n",
    "\n",
    "                        decrypted_maps[k, p] = decrypted\n",
    "\n",
    "                # Reshape to feature map: (num_kernels, H, W)\n",
    "                feature_maps_b = decrypted_maps.view(num_kernels, H, W)\n",
    "                feature_maps_batch.append(feature_maps_b)\n",
    "\n",
    "            x = torch.stack(feature_maps_batch, dim=0)  # (B, num_kernels, H, W)\n",
    "\n",
    "            x = self.pool1(F.relu(self.bn1(x)))\n",
    "\n",
    "        else:\n",
    "            x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "\n",
    "        # use regular forward pass for remaining layers\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "\n",
    "        # Flatten and fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ],
   "id": "e796720223be2333",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize IPFE-enhanced CNN\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ipfe_model = IPFECNN(num_classes=10, prime=104729).to(device)\n",
    "\n",
    "print(f\"IPFE-CNN model created on device: {device}\")"
   ],
   "id": "333e22ae6922500",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test IPFE functionality with a sample\n",
    "def test_ipfe_cnn(model, test_loader, device, num_samples=5):\n",
    "    \"\"\"Test the IPFE-CNN with a sample query vector\"\"\"\n",
    "    model.eval()\n",
    "    # x is 784 big\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of test data\n",
    "        data_iter = iter(test_loader)\n",
    "        images, labels = next(data_iter)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        print(f\"Labels of test samples: {labels[:num_samples].cpu().numpy()}\")\n",
    "\n",
    "        # Test regular forward pass\n",
    "        print(\"Testing regular forward pass...\")\n",
    "        regular_outputs = model(images[:num_samples])\n",
    "        _, regular_predicted = regular_outputs.max(1)\n",
    "        print(\"Regular predictions:\", regular_predicted.cpu().numpy())\n",
    "\n",
    "        # Test IPFE forward pass\n",
    "        print(\"Testing IPFE forward pass...\")\n",
    "        try:\n",
    "            ipfe_outputs = model.forward(images[:num_samples], encrypted=True)\n",
    "            _, ipfe_predicted = ipfe_outputs.max(1)\n",
    "\n",
    "            print(f\"Regular predictions: {regular_predicted.cpu().numpy()}\")\n",
    "            print(f\"IPFE predictions: {ipfe_predicted.cpu().numpy()}\")\n",
    "            print(f\"True labels: {labels[:num_samples].cpu().numpy()}\")\n",
    "\n",
    "            # Compare results\n",
    "            matches = (regular_predicted == ipfe_predicted).sum().item()\n",
    "            print(f\"Prediction matches between regular and IPFE: {matches}/{num_samples}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"IPFE forward pass failed: {e}\")\n",
    "\n",
    "# Test the IPFE functionality\n",
    "print(\"Testing IPFE-CNN functionality...\")\n",
    "test_ipfe_cnn(ipfe_model, test_loader, device)\n"
   ],
   "id": "cd257fc471f05451",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Old try",
   "id": "7d9cc034993ee210"
  },
  {
   "cell_type": "code",
   "id": "f1b915ff",
   "metadata": {},
   "source": [
    "# # Define IPFE-enhanced CNN with functional encryption\n",
    "# class IPFECNN(nn.Module):\n",
    "#     def __init__(self, num_classes=10, prime=104729):\n",
    "#         super(IPFECNN, self).__init__()\n",
    "#         self.prime = prime\n",
    "#         self.ipfe = IPFE(prime)\n",
    "#         self.input_size = None\n",
    "#         self.ipfe.setup(28*28)\n",
    "#         print(\"IPFE setup done\")\n",
    "#\n",
    "#\n",
    "#         # First convolutional block - this will be used with IPFE\n",
    "#         self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(16)\n",
    "#         self.pool1 = nn.MaxPool2d(2, 2)\n",
    "#\n",
    "#         # Second convolutional block\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.bn2 = nn.BatchNorm2d(32)\n",
    "#         self.pool2 = nn.MaxPool2d(2, 2)\n",
    "#\n",
    "#         # Third convolutional block\n",
    "#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.bn3 = nn.BatchNorm2d(64)\n",
    "#         self.pool3 = nn.MaxPool2d(2, 2)\n",
    "#\n",
    "#         # Fully connected layers\n",
    "#         self.fc1 = nn.Linear(64 * 3 * 3, 128)\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "#         self.fc2 = nn.Linear(128, num_classes)\n",
    "#\n",
    "#         # IPFE setup for first conv layer\n",
    "#         self.ipfe_setup_done = False\n",
    "#\n",
    "#\n",
    "#     def forward(self, x, y_vector=None):\n",
    "#\n",
    "#         # If y_vector is provided, use IPFE for first conv\n",
    "#         if y_vector is not None:\n",
    "#\n",
    "#             if not self.ipfe_setup_done:\n",
    "#                 self.setup_ipfe()\n",
    "#\n",
    "#             self.ipfe.key_derive(y_vector)\n",
    "#             print(f\"IPFE key derivation complete for provided query vector\")\n",
    "#\n",
    "#             # Encrypt the input x (flattened)\n",
    "#             x_flat = x.view(x.size(0), -1).cpu().numpy()\n",
    "#\n",
    "#             # For each sample in the batch, compute IPFE\n",
    "#             ipfe_results = []\n",
    "#             for x_i in x_flat:\n",
    "#                 # Convert input to integers\n",
    "#                 x_int = [int(val * 1000) % (self.prime - 1) for val in x_i]\n",
    "#\n",
    "#                 print(\"<x, y> (expected):\", sum((xi * yi) for xi, yi in zip(x_int, y_vector)) % (self.prime - 1))\n",
    "#\n",
    "#                 # Encrypt input\n",
    "#                 ct = self.ipfe.encrypt(x_int)\n",
    "#\n",
    "#                 # Decrypt to get inner product\n",
    "#                 try:\n",
    "#                     inner_product = self.ipfe.decrypt(ct)\n",
    "#\n",
    "#                     print(\"<x, y> (decrypted):\", inner_product)\n",
    "#\n",
    "#                     ipfe_results.append(inner_product)\n",
    "#                 except:\n",
    "#                     print(\"IPFE decryption failed\")\n",
    "#                     # Fallback to regular computation if IPFE fails\n",
    "#                     inner_product = sum(xi * yi for xi, yi in zip(x_int, y_vector)) % (self.prime - 1)\n",
    "#                     ipfe_results.append(inner_product)\n",
    "#\n",
    "#             # Convert IPFE results back to tensor\n",
    "#             ipfe_tensor = torch.tensor(ipfe_results, dtype=torch.float32).to(x.device)\n",
    "#\n",
    "#         # apply CNN normal\n",
    "#\n",
    "#         x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "#\n",
    "#         # Continue with remaining layers\n",
    "#         x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "#         x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "#\n",
    "#         # Flatten and fully connected layers\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.fc2(x)\n",
    "#\n",
    "#         return x\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### run IPFE-CNN",
   "id": "603797d67ee9a810"
  },
  {
   "cell_type": "code",
   "id": "f05c5ec7",
   "metadata": {},
   "source": [
    "# Initialize IPFE-enhanced CNN\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ipfe_model = IPFECNN(num_classes=10, prime=104729).to(device)\n",
    "\n",
    "# Copy weights from the trained model\n",
    "ipfe_model.load_state_dict(model.state_dict())\n",
    "\n",
    "ipfe_model.setup_ipfe()\n",
    "\n",
    "print(f\"IPFE-CNN model created on device: {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in ipfe_model.parameters()):,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(ipfe_model.conv1_length)",
   "id": "61e2ae2d1d73ad79",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "968c6276",
   "metadata": {},
   "source": [
    "# Test IPFE functionality with a sample\n",
    "def test_ipfe_cnn(model, test_loader, device, num_samples=5):\n",
    "    \"\"\"Test the IPFE-CNN with a sample query vector\"\"\"\n",
    "    model.eval()\n",
    "    # x is 784 big\n",
    "\n",
    "    # Create a sample query vector y (same length as flattened conv1 weights)\n",
    "    y_vector = [1] * model.conv1_length  # Simple query vector of all 1s\n",
    "    print(\"Using query vector y of length:\", len(y_vector))\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of test data\n",
    "        data_iter = iter(test_loader)\n",
    "        images, labels = next(data_iter)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        print(f\"Labels of test samples: {labels[:num_samples].cpu().numpy()}\")\n",
    "\n",
    "        # Test regular forward pass\n",
    "        print(\"Testing regular forward pass...\")\n",
    "        regular_outputs = model(images[:num_samples])\n",
    "        _, regular_predicted = regular_outputs.max(1)\n",
    "        print(\"Regular predictions:\", regular_predicted.cpu().numpy())\n",
    "\n",
    "        # Test IPFE forward pass\n",
    "        print(\"Testing IPFE forward pass...\")\n",
    "        try:\n",
    "            ipfe_outputs = model.forward_with_ipfe(images[:num_samples], y_vector)\n",
    "            _, ipfe_predicted = ipfe_outputs.max(1)\n",
    "\n",
    "            print(f\"Regular predictions: {regular_predicted.cpu().numpy()}\")\n",
    "            print(f\"IPFE predictions: {ipfe_predicted.cpu().numpy()}\")\n",
    "            print(f\"True labels: {labels[:num_samples].cpu().numpy()}\")\n",
    "\n",
    "            # Compare results\n",
    "            matches = (regular_predicted == ipfe_predicted).sum().item()\n",
    "            print(f\"Prediction matches between regular and IPFE: {matches}/{num_samples}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"IPFE forward pass failed: {e}\")\n",
    "\n",
    "# Test the IPFE functionality\n",
    "print(\"Testing IPFE-CNN functionality...\")\n",
    "test_ipfe_cnn(ipfe_model, test_loader, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4356635b",
   "metadata": {},
   "source": [
    "# Demonstrate IPFE with different query vectors\n",
    "def demonstrate_ipfe_queries(model, test_loader, device):\n",
    "    \"\"\"Demonstrate IPFE with different query vectors\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a single test sample\n",
    "    data_iter = iter(test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    single_image = images[0:1].to(device)  # Single sample\n",
    "    true_label = labels[0].item()\n",
    "    \n",
    "    print(f\"Testing with image of digit: {true_label}\")\n",
    "    \n",
    "    # Different query vectors to test\n",
    "    query_vectors = {\n",
    "        \"All ones\": [1] * model.conv1_length,\n",
    "        \"All zeros\": [0] * model.conv1_length,\n",
    "        \"Alternating\": [1 if i % 2 == 0 else -1 for i in range(model.conv1_length)],\n",
    "        \"Random\": [1, 0, 1, 0] * (model.conv1_length // 4) + [1] * (model.conv1_length % 4)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nTesting different query vectors:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for name, y_vector in query_vectors.items():\n",
    "        try:\n",
    "            # Regular forward pass\n",
    "            regular_output = model(single_image)\n",
    "            regular_pred = regular_output.max(1)[1].item()\n",
    "            \n",
    "            # IPFE forward pass\n",
    "            ipfe_output = model.forward_with_ipfe(single_image, y_vector)\n",
    "            ipfe_pred = ipfe_output.max(1)[1].item()\n",
    "            \n",
    "            print(f\"{name:15} - Regular: {regular_pred}, IPFE: {ipfe_pred}, Match: {regular_pred == ipfe_pred}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{name:15} - IPFE failed: {str(e)[:50]}...\")\n",
    "\n",
    "# Demonstrate with different queries\n",
    "print(\"Demonstrating IPFE with different query vectors...\")\n",
    "demonstrate_ipfe_queries(ipfe_model, test_loader, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "87803409",
   "metadata": {},
   "source": [
    "# Visualize the first CNN layer's filters (weights)\n",
    "def visualize_first_cnn_layer(model):\n",
    "    \"\"\"Visualize the first convolutional layer filters\"\"\"\n",
    "    # Find the first conv layer\n",
    "    first_conv = None\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, torch.nn.Conv2d):\n",
    "            first_conv = m\n",
    "            break\n",
    "    if first_conv is None:\n",
    "        print(\"No Conv2d layer found in model.\")\n",
    "        return\n",
    "\n",
    "    weights = first_conv.weight.data.cpu()\n",
    "    num_filters = weights.shape[0]\n",
    "\n",
    "    # Calculate grid size\n",
    "    cols = 8\n",
    "    rows = (num_filters + cols - 1) // cols\n",
    "\n",
    "    plt.figure(figsize=(cols*1.5, rows*1.5))\n",
    "    for i in range(num_filters):\n",
    "        ax = plt.subplot(rows, cols, i+1)\n",
    "        # For grayscale, show as [out_ch, in_ch, H, W]\n",
    "        w = weights[i, 0].numpy()\n",
    "        ax.imshow(w, cmap='gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'F{i}')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"First Conv Layer Filters (IPFE-enhanced)\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualizing first CNN layer filters...\")\n",
    "visualize_first_cnn_layer(ipfe_model)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cbc48825",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
