{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "c2760c72956b3d3"
  },
  {
   "cell_type": "code",
   "id": "c29d01d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T19:04:40.748350Z",
     "start_time": "2025-10-23T19:04:40.087257Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "81bbf67e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T19:04:46.521513Z",
     "start_time": "2025-10-23T19:04:40.976278Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Trained CNN",
   "id": "ca69fe0bf0214053"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T19:04:46.589824Z",
     "start_time": "2025-10-23T19:04:46.539338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda pic: torch.tensor(np.array(pic), dtype=torch.float32).unsqueeze(0))\n",
    "])\n",
    "\n",
    "# Load training and test datasets\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ],
   "id": "ec44f3165f628cc6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "8f8ff355",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T19:04:46.625515Z",
     "start_time": "2025-10-23T19:04:46.616176Z"
    }
   },
   "source": [
    "# Define a lightweight CNN architecture\n",
    "class LightweightCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LightweightCNN, self).__init__()\n",
    "\n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 128)  # 28x28 -> 14x14 -> 7x7 -> 3x3 after pooling\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        # Flatten and fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T19:04:46.651461Z",
     "start_time": "2025-10-23T19:04:46.645782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.01)  # smaller std for large inputs\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)"
   ],
   "id": "7693a69ca22d4ca5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "fb3f84ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T19:04:46.687618Z",
     "start_time": "2025-10-23T19:04:46.675074Z"
    }
   },
   "source": [
    "# Initialize the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LightweightCNN(num_classes=10).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "print(f\"Model created on device: {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created on device: cpu\n",
      "Total parameters: 98,666\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "fe24be06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T19:06:05.936613Z",
     "start_time": "2025-10-23T19:04:46.706560Z"
    }
   },
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, device, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "            \n",
    "            if batch_idx % 200 == 0:\n",
    "                print(f'Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(train_loader)}, '\n",
    "                      f'Loss: {loss.item():.4f}, Accuracy: {100.*correct/total:.2f}%')\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        print(f'Epoch {epoch+1} completed - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "        print('-' * 50)\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "train_model(model, train_loader, criterion, optimizer, device, epochs=3)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/3, Batch 0/938, Loss: 2.2977, Accuracy: 14.06%\n",
      "Epoch 1/3, Batch 200/938, Loss: 0.1743, Accuracy: 81.77%\n",
      "Epoch 1/3, Batch 400/938, Loss: 0.1358, Accuracy: 88.68%\n",
      "Epoch 1/3, Batch 600/938, Loss: 0.0955, Accuracy: 91.29%\n",
      "Epoch 1/3, Batch 800/938, Loss: 0.0115, Accuracy: 92.84%\n",
      "Epoch 1 completed - Loss: 0.2278, Accuracy: 93.55%\n",
      "--------------------------------------------------\n",
      "Epoch 2/3, Batch 0/938, Loss: 0.0471, Accuracy: 98.44%\n",
      "Epoch 2/3, Batch 200/938, Loss: 0.0148, Accuracy: 97.54%\n",
      "Epoch 2/3, Batch 400/938, Loss: 0.0172, Accuracy: 97.77%\n",
      "Epoch 2/3, Batch 600/938, Loss: 0.0682, Accuracy: 97.82%\n",
      "Epoch 2/3, Batch 800/938, Loss: 0.0140, Accuracy: 97.96%\n",
      "Epoch 2 completed - Loss: 0.0674, Accuracy: 97.98%\n",
      "--------------------------------------------------\n",
      "Epoch 3/3, Batch 0/938, Loss: 0.0295, Accuracy: 100.00%\n",
      "Epoch 3/3, Batch 200/938, Loss: 0.0473, Accuracy: 98.45%\n",
      "Epoch 3/3, Batch 400/938, Loss: 0.0348, Accuracy: 98.39%\n",
      "Epoch 3/3, Batch 600/938, Loss: 0.0315, Accuracy: 98.43%\n",
      "Epoch 3/3, Batch 800/938, Loss: 0.0464, Accuracy: 98.46%\n",
      "Epoch 3 completed - Loss: 0.0512, Accuracy: 98.44%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "3ec1ed97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T19:06:08.050858Z",
     "start_time": "2025-10-23T19:06:05.969530Z"
    }
   },
   "source": [
    "# Test the model\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the trained model\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_accuracy = test_model(model, test_loader, device)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on test set...\n",
      "Test Loss: 0.0334\n",
      "Test Accuracy: 98.84%\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "d66e75db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T19:06:08.550819Z",
     "start_time": "2025-10-23T19:06:08.074444Z"
    }
   },
   "source": [
    "# Visualize some predictions\n",
    "def visualize_predictions(model, test_loader, device, num_samples=8):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of test data\n",
    "        data_iter = iter(test_loader)\n",
    "        images, labels = next(data_iter)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        \n",
    "        # Move back to CPU for visualization\n",
    "        images = images.cpu()\n",
    "        labels = labels.cpu()\n",
    "        predicted = predicted.cpu()\n",
    "\n",
    "        img = images[0]\n",
    "\n",
    "        img_np = img.squeeze().numpy()  # remove channel dimension\n",
    "\n",
    "        print(\"Pixel values of the first image:\")\n",
    "        print(img_np)\n",
    "\n",
    "        print(f\"Min value: {img_np.min()}, Max value: {img_np.max()}\")\n",
    "\n",
    "        # Create subplot\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "        axes = axes.ravel()\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            axes[i].imshow(images[i].squeeze(), cmap='gray')\n",
    "            axes[i].set_title(f'True: {labels[i].item()}, Pred: {predicted[i].item()}')\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Visualize predictions\n",
    "print(\"Visualizing some predictions...\")\n",
    "visualize_predictions(model, test_loader, device)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing some predictions...\n",
      "Pixel values of the first image:\n",
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.  84. 185. 159. 151.  60.  36.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0. 222. 254. 254. 254. 254. 241. 198. 198.\n",
      "  198. 198. 198. 198. 198. 198. 170.  52.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.  67. 114.  72. 114. 163. 227. 254. 225.\n",
      "  254. 254. 254. 250. 229. 254. 254. 140.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  17.  66.  14.\n",
      "   67.  67.  67.  59.  21. 236. 254. 106.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.  83. 253. 209.  18.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.  22. 233. 255.  83.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0. 129. 254. 238.  44.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.  59. 249. 254.  62.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0. 133. 254. 187.   5.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   9. 205. 248.  58.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0. 126. 254. 182.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   75. 251. 240.  57.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  19.\n",
      "  221. 254. 166.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3. 203.\n",
      "  254. 219.  35.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  38. 254.\n",
      "  254.  77.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  31. 224. 254.\n",
      "  115.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 133. 254. 254.\n",
      "   52.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  61. 242. 254. 254.\n",
      "   52.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 121. 254. 254. 219.\n",
      "   40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 121. 254. 207.  18.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n",
      "Min value: 0.0, Max value: 255.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 8 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "a670e23b",
   "metadata": {},
   "source": "## IPFE-enhanced CNN"
  },
  {
   "cell_type": "code",
   "id": "e7a0076c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T19:06:08.587281Z",
     "start_time": "2025-10-23T19:06:08.572405Z"
    }
   },
   "source": [
    "# import ipfe functions\n",
    "from altered_ipfe import IPFE"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### current try",
   "id": "a0e9809d3ef7052c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In the First layer we applied 16 filters of size 3x3, with input channel 1 (grayscale), so the total number of parameters is 16 * 3 * 3 * 1 = 144.\n",
    "\n",
    "So With that each y is one filter flattened to a vector of length 9.\n",
    "For an input x of size 28x28, flattened to a vector of length 784, we can compute the inner product <x, y> for each filter y.\n",
    "\n",
    "Option 1 encrypt the entire input x of length 784, and padd the y to a length of 784 with zeros. -> This will be inefficient as the IPFE scheme will have to handle large vectors.\n",
    "\n",
    "Option 2 encrypt patches of x corresponding to the filter size (3x3 = 9 elements), and compute the inner product for each patch with the filter y. This requires sliding the filter over the input image and encrypting each patch separately.\n",
    "\n",
    "1. Step: Create patches of size 3x3 from the input image (28x28) -> This will create 28x28 patches (with padding). => 784 patches\n",
    "2. Step: Encrypt each patch separately.\n",
    "3. Step: Create 16 query vectors y (one for each filter), each of size 9 (3x3 flattened). => Create a Key for each vector\n",
    "4. Step: decrypt each inner product result to get the convolution output."
   ],
   "id": "e412789862c18ee8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T19:06:08.614332Z",
     "start_time": "2025-10-23T19:06:08.599694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class IPFECNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, prime=1000000007):\n",
    "        super(IPFECNN, self).__init__()\n",
    "        self.prime = prime\n",
    "        self.ipfe = IPFE(prime)\n",
    "        self.encryption_length = 9 # 3x3 filter size flattened\n",
    "\n",
    "        self.ipfe.setup(self.encryption_length)\n",
    "        print(\"IPFE setup done, with length:\", self.encryption_length)\n",
    "\n",
    "        # First convolutional block - this will be used with IPFE\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "        #copy weights from the trained model\n",
    "        self.load_state_dict(model.state_dict())\n",
    "        print(\"weights copied from trained model\")\n",
    "\n",
    "        self.weights = self.conv1.weight.data\n",
    "        self.y_array = torch.round(self.weights.view(self.weights.size(0), -1).squeeze(1).view(self.weights.size(0), -1) * 10000).long().tolist()\n",
    "        print(\"weights converted to y vectors\")\n",
    "        self.biases = self.conv1.bias\n",
    "        print(\"biases saved\")\n",
    "        self.sk_y_array = [self.ipfe.key_derive(y) for y in self.y_array]\n",
    "        print(\"sk_ys created\")\n",
    "\n",
    "    def first_conv_forward(self, x, encrypted=False):\n",
    "        if encrypted:\n",
    "            batch_size = x.shape[0]\n",
    "            H, W = x.shape[2], x.shape[3]\n",
    "\n",
    "            unfold = nn.Unfold(kernel_size=3, stride=1, padding=1)\n",
    "            patches = unfold(x)\n",
    "\n",
    "            num_patches = patches.shape[-1]\n",
    "            num_kernels = len(self.sk_y_array)\n",
    "\n",
    "            feature_maps_batch = []\n",
    "\n",
    "            for b in range(batch_size):\n",
    "                patches_b = patches[b].T\n",
    "                decrypted_maps = torch.zeros(num_kernels, num_patches, device=x.device)\n",
    "\n",
    "                # Loop over patches and kernels\n",
    "                for p in range(num_patches):\n",
    "                    patch = patches_b[p]\n",
    "                    patch_int = [(int(val.item()) % (self.prime - 1)) for val in patch]\n",
    "                    encrypted = self.ipfe.encrypt(patch_int)\n",
    "\n",
    "                    for k in range(num_kernels):\n",
    "                        decrypted_scaled = self.ipfe.decrypt(encrypted, self.sk_y_array[k], self.y_array[k])\n",
    "\n",
    "                        decrypted = (decrypted_scaled / 10000) + self.biases[k].item() # bias needed W*X + B\n",
    "                        # (x1*y1*10000 + x2*y2*10000 + x3*y3*10000)/10000 = (x1*y1 + x2*y2 + x3*y3)\n",
    "\n",
    "                        decrypted_maps[k, p] = decrypted\n",
    "\n",
    "                # Reshape to feature map: (num_kernels, H, W)\n",
    "                feature_maps_b = decrypted_maps.view(num_kernels, H, W)\n",
    "                feature_maps_batch.append(feature_maps_b)\n",
    "\n",
    "            x_ipfe = torch.stack(feature_maps_batch, dim=0)  # (B, num_kernels, H, W)\n",
    "            # x_conv = self.conv1(x)\n",
    "            #\n",
    "            # b = 0\n",
    "            #\n",
    "            # diff = (x_conv - x_ipfe).abs()\n",
    "            # for c in range(num_kernels):\n",
    "            #     H, W= x_conv.shape[2], x_conv.shape[3]\n",
    "            #     h0, w0 = H // 2 - 2, W // 2 - 2  # top-left corner of 5x5 center\n",
    "            #     h1, w1 = h0 + 5, w0 + 5          # bottom-right corner\n",
    "            #\n",
    "            #     conv_center = x_conv[b, c, h0:h1, w0:w1].detach().cpu()\n",
    "            #     ipfe_center = x_ipfe[b, c, h0:h1, w0:w1].detach().cpu()\n",
    "            #     diff_center = diff[b, c, h0:h1, w0:w1].detach().cpu()\n",
    "            #\n",
    "            #     print(f\"\\n=== Kernel {c} — Center 5×5 Region ===\")\n",
    "            #     print(\"Conv Output:\\n\", conv_center)\n",
    "            #     print(\"IPFE Output:\\n\", ipfe_center)\n",
    "            #     print(\"|Difference|:\\n\", diff_center)\n",
    "            #\n",
    "            # for c in range(num_kernels):\n",
    "            #     plt.figure(figsize=(9, 3))\n",
    "            #\n",
    "            #     # Conv Output\n",
    "            #     plt.subplot(1, 3, 1)\n",
    "            #     plt.imshow(x_conv[b, c].detach().cpu(), cmap=\"viridis\")\n",
    "            #     plt.title(f\"Conv Output (Kernel {c})\")\n",
    "            #     plt.axis(\"off\")\n",
    "            #\n",
    "            #     # IPFE Output\n",
    "            #     plt.subplot(1, 3, 2)\n",
    "            #     plt.imshow(x_ipfe[b, c].detach().cpu(), cmap=\"viridis\")\n",
    "            #     plt.title(f\"IPFE Output (Kernel {c})\")\n",
    "            #     plt.axis(\"off\")\n",
    "            #\n",
    "            #     # |Difference|\n",
    "            #     plt.subplot(1, 3, 3)\n",
    "            #     plt.imshow((x_conv[b, c] - x_ipfe[b, c]).abs().detach().cpu(), cmap=\"magma\")\n",
    "            #     plt.title(\"|Difference|\")\n",
    "            #     plt.axis(\"off\")\n",
    "            #\n",
    "            #     plt.tight_layout()\n",
    "            #     plt.show()\n",
    "\n",
    "            return x_ipfe\n",
    "\n",
    "        else:\n",
    "            return self.conv1(x)\n",
    "\n",
    "    def forward(self, x, encrypted=False):\n",
    "\n",
    "        x = self.first_conv_forward(x, encrypted)\n",
    "        x = self.pool1(F.relu(self.bn1(x)))\n",
    "\n",
    "        # use regular forward pass for remaining layers\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "\n",
    "        # Flatten and fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ],
   "id": "e796720223be2333",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T19:06:08.639092Z",
     "start_time": "2025-10-23T19:06:08.629400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize IPFE-enhanced CNN\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ipfe_model = IPFECNN(num_classes=10, prime=1000000007).to(device)\n",
    "\n",
    "print(f\"IPFE-CNN model created on device: {device}\")"
   ],
   "id": "333e22ae6922500",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPFE setup done, with length: 9\n",
      "weights copied from trained model\n",
      "weights converted to y vectors\n",
      "biases saved\n",
      "sk_ys created\n",
      "IPFE-CNN model created on device: cpu\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T19:16:14.476635Z",
     "start_time": "2025-10-23T19:09:02.705516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test IPFE functionality with a sample\n",
    "def test_ipfe_cnn(model, test_loader, device, num_samples=5):\n",
    "    \"\"\"Test the IPFE-CNN with a sample query vector\"\"\"\n",
    "    model.eval()\n",
    "    # x is 784 big\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of test data\n",
    "        data_iter = iter(test_loader)\n",
    "        images, labels = next(data_iter)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        print(f\"Labels of test samples: {labels[:num_samples].cpu().numpy()}\")\n",
    "\n",
    "        # Test regular forward pass\n",
    "        print(\"Testing regular forward pass...\")\n",
    "        regular_outputs = model(images[:num_samples])\n",
    "        _, regular_predicted = regular_outputs.max(1)\n",
    "        print(\"Regular predictions:\", regular_predicted.cpu().numpy())\n",
    "\n",
    "        # Test IPFE forward pass\n",
    "        print(\"Testing IPFE forward pass...\")\n",
    "        try:\n",
    "            ipfe_outputs = model.forward(images[:num_samples], encrypted=True)\n",
    "            _, ipfe_predicted = ipfe_outputs.max(1)\n",
    "\n",
    "            print(f\"IPFE predictions: {ipfe_predicted.cpu().numpy()}\")\n",
    "\n",
    "            # Compare results\n",
    "            matches = (regular_predicted == ipfe_predicted).sum().item()\n",
    "            print(f\"Prediction matches between regular and IPFE: {matches}/{num_samples}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"IPFE forward pass failed: {e}\")\n",
    "\n",
    "# Test the IPFE functionality\n",
    "print(\"Testing IPFE-CNN functionality...\")\n",
    "test_ipfe_cnn(ipfe_model, test_loader, device)\n"
   ],
   "id": "cd257fc471f05451",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing IPFE-CNN functionality...\n",
      "Labels of test samples: [7 2 1 0 4]\n",
      "Testing regular forward pass...\n",
      "Regular predictions: [7 2 1 0 4]\n",
      "Testing IPFE forward pass...\n",
      "IPFE predictions: [7 2 1 0 4]\n",
      "Prediction matches between regular and IPFE: 5/5\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Old try",
   "id": "7d9cc034993ee210"
  },
  {
   "cell_type": "code",
   "id": "f1b915ff",
   "metadata": {},
   "source": [
    "# # Define IPFE-enhanced CNN with functional encryption\n",
    "# class IPFECNN(nn.Module):\n",
    "#     def __init__(self, num_classes=10, prime=104729):\n",
    "#         super(IPFECNN, self).__init__()\n",
    "#         self.prime = prime\n",
    "#         self.ipfe = IPFE(prime)\n",
    "#         self.input_size = None\n",
    "#         self.ipfe.setup(28*28)\n",
    "#         print(\"IPFE setup done\")\n",
    "#\n",
    "#\n",
    "#         # First convolutional block - this will be used with IPFE\n",
    "#         self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(16)\n",
    "#         self.pool1 = nn.MaxPool2d(2, 2)\n",
    "#\n",
    "#         # Second convolutional block\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.bn2 = nn.BatchNorm2d(32)\n",
    "#         self.pool2 = nn.MaxPool2d(2, 2)\n",
    "#\n",
    "#         # Third convolutional block\n",
    "#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.bn3 = nn.BatchNorm2d(64)\n",
    "#         self.pool3 = nn.MaxPool2d(2, 2)\n",
    "#\n",
    "#         # Fully connected layers\n",
    "#         self.fc1 = nn.Linear(64 * 3 * 3, 128)\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "#         self.fc2 = nn.Linear(128, num_classes)\n",
    "#\n",
    "#         # IPFE setup for first conv layer\n",
    "#         self.ipfe_setup_done = False\n",
    "#\n",
    "#\n",
    "#     def forward(self, x, y_vector=None):\n",
    "#\n",
    "#         # If y_vector is provided, use IPFE for first conv\n",
    "#         if y_vector is not None:\n",
    "#\n",
    "#             if not self.ipfe_setup_done:\n",
    "#                 self.setup_ipfe()\n",
    "#\n",
    "#             self.ipfe.key_derive(y_vector)\n",
    "#             print(f\"IPFE key derivation complete for provided query vector\")\n",
    "#\n",
    "#             # Encrypt the input x (flattened)\n",
    "#             x_flat = x.view(x.size(0), -1).cpu().numpy()\n",
    "#\n",
    "#             # For each sample in the batch, compute IPFE\n",
    "#             ipfe_results = []\n",
    "#             for x_i in x_flat:\n",
    "#                 # Convert input to integers\n",
    "#                 x_int = [int(val * 1000) % (self.prime - 1) for val in x_i]\n",
    "#\n",
    "#                 print(\"<x, y> (expected):\", sum((xi * yi) for xi, yi in zip(x_int, y_vector)) % (self.prime - 1))\n",
    "#\n",
    "#                 # Encrypt input\n",
    "#                 ct = self.ipfe.encrypt(x_int)\n",
    "#\n",
    "#                 # Decrypt to get inner product\n",
    "#                 try:\n",
    "#                     inner_product = self.ipfe.decrypt(ct)\n",
    "#\n",
    "#                     print(\"<x, y> (decrypted):\", inner_product)\n",
    "#\n",
    "#                     ipfe_results.append(inner_product)\n",
    "#                 except:\n",
    "#                     print(\"IPFE decryption failed\")\n",
    "#                     # Fallback to regular computation if IPFE fails\n",
    "#                     inner_product = sum(xi * yi for xi, yi in zip(x_int, y_vector)) % (self.prime - 1)\n",
    "#                     ipfe_results.append(inner_product)\n",
    "#\n",
    "#             # Convert IPFE results back to tensor\n",
    "#             ipfe_tensor = torch.tensor(ipfe_results, dtype=torch.float32).to(x.device)\n",
    "#\n",
    "#         # apply CNN normal\n",
    "#\n",
    "#         x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "#\n",
    "#         # Continue with remaining layers\n",
    "#         x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "#         x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "#\n",
    "#         # Flatten and fully connected layers\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.fc2(x)\n",
    "#\n",
    "#         return x\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### run IPFE-CNN",
   "id": "603797d67ee9a810"
  },
  {
   "cell_type": "code",
   "id": "f05c5ec7",
   "metadata": {},
   "source": [
    "# Initialize IPFE-enhanced CNN\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ipfe_model = IPFECNN(num_classes=10, prime=104729).to(device)\n",
    "\n",
    "# Copy weights from the trained model\n",
    "ipfe_model.load_state_dict(model.state_dict())\n",
    "\n",
    "ipfe_model.setup_ipfe()\n",
    "\n",
    "print(f\"IPFE-CNN model created on device: {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in ipfe_model.parameters()):,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(ipfe_model.conv1_length)",
   "id": "61e2ae2d1d73ad79",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "968c6276",
   "metadata": {},
   "source": [
    "# Test IPFE functionality with a sample\n",
    "def test_ipfe_cnn(model, test_loader, device, num_samples=5):\n",
    "    \"\"\"Test the IPFE-CNN with a sample query vector\"\"\"\n",
    "    model.eval()\n",
    "    # x is 784 big\n",
    "\n",
    "    # Create a sample query vector y (same length as flattened conv1 weights)\n",
    "    y_vector = [1] * model.conv1_length  # Simple query vector of all 1s\n",
    "    print(\"Using query vector y of length:\", len(y_vector))\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of test data\n",
    "        data_iter = iter(test_loader)\n",
    "        images, labels = next(data_iter)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        print(f\"Labels of test samples: {labels[:num_samples].cpu().numpy()}\")\n",
    "\n",
    "        # Test regular forward pass\n",
    "        print(\"Testing regular forward pass...\")\n",
    "        regular_outputs = model(images[:num_samples])\n",
    "        _, regular_predicted = regular_outputs.max(1)\n",
    "        print(\"Regular predictions:\", regular_predicted.cpu().numpy())\n",
    "\n",
    "        # Test IPFE forward pass\n",
    "        print(\"Testing IPFE forward pass...\")\n",
    "        try:\n",
    "            ipfe_outputs = model.forward_with_ipfe(images[:num_samples], y_vector)\n",
    "            _, ipfe_predicted = ipfe_outputs.max(1)\n",
    "\n",
    "            print(f\"Regular predictions: {regular_predicted.cpu().numpy()}\")\n",
    "            print(f\"IPFE predictions: {ipfe_predicted.cpu().numpy()}\")\n",
    "            print(f\"True labels: {labels[:num_samples].cpu().numpy()}\")\n",
    "\n",
    "            # Compare results\n",
    "            matches = (regular_predicted == ipfe_predicted).sum().item()\n",
    "            print(f\"Prediction matches between regular and IPFE: {matches}/{num_samples}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"IPFE forward pass failed: {e}\")\n",
    "\n",
    "# Test the IPFE functionality\n",
    "print(\"Testing IPFE-CNN functionality...\")\n",
    "test_ipfe_cnn(ipfe_model, test_loader, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4356635b",
   "metadata": {},
   "source": [
    "# Demonstrate IPFE with different query vectors\n",
    "def demonstrate_ipfe_queries(model, test_loader, device):\n",
    "    \"\"\"Demonstrate IPFE with different query vectors\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a single test sample\n",
    "    data_iter = iter(test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    single_image = images[0:1].to(device)  # Single sample\n",
    "    true_label = labels[0].item()\n",
    "    \n",
    "    print(f\"Testing with image of digit: {true_label}\")\n",
    "    \n",
    "    # Different query vectors to test\n",
    "    query_vectors = {\n",
    "        \"All ones\": [1] * model.conv1_length,\n",
    "        \"All zeros\": [0] * model.conv1_length,\n",
    "        \"Alternating\": [1 if i % 2 == 0 else -1 for i in range(model.conv1_length)],\n",
    "        \"Random\": [1, 0, 1, 0] * (model.conv1_length // 4) + [1] * (model.conv1_length % 4)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nTesting different query vectors:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for name, y_vector in query_vectors.items():\n",
    "        try:\n",
    "            # Regular forward pass\n",
    "            regular_output = model(single_image)\n",
    "            regular_pred = regular_output.max(1)[1].item()\n",
    "            \n",
    "            # IPFE forward pass\n",
    "            ipfe_output = model.forward_with_ipfe(single_image, y_vector)\n",
    "            ipfe_pred = ipfe_output.max(1)[1].item()\n",
    "            \n",
    "            print(f\"{name:15} - Regular: {regular_pred}, IPFE: {ipfe_pred}, Match: {regular_pred == ipfe_pred}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{name:15} - IPFE failed: {str(e)[:50]}...\")\n",
    "\n",
    "# Demonstrate with different queries\n",
    "print(\"Demonstrating IPFE with different query vectors...\")\n",
    "demonstrate_ipfe_queries(ipfe_model, test_loader, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "87803409",
   "metadata": {},
   "source": [
    "# Visualize the first CNN layer's filters (weights)\n",
    "def visualize_first_cnn_layer(model):\n",
    "    \"\"\"Visualize the first convolutional layer filters\"\"\"\n",
    "    # Find the first conv layer\n",
    "    first_conv = None\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, torch.nn.Conv2d):\n",
    "            first_conv = m\n",
    "            break\n",
    "    if first_conv is None:\n",
    "        print(\"No Conv2d layer found in model.\")\n",
    "        return\n",
    "\n",
    "    weights = first_conv.weight.data.cpu()\n",
    "    num_filters = weights.shape[0]\n",
    "\n",
    "    # Calculate grid size\n",
    "    cols = 8\n",
    "    rows = (num_filters + cols - 1) // cols\n",
    "\n",
    "    plt.figure(figsize=(cols*1.5, rows*1.5))\n",
    "    for i in range(num_filters):\n",
    "        ax = plt.subplot(rows, cols, i+1)\n",
    "        # For grayscale, show as [out_ch, in_ch, H, W]\n",
    "        w = weights[i, 0].numpy()\n",
    "        ax.imshow(w, cmap='gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'F{i}')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"First Conv Layer Filters (IPFE-enhanced)\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualizing first CNN layer filters...\")\n",
    "visualize_first_cnn_layer(ipfe_model)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cbc48825",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
