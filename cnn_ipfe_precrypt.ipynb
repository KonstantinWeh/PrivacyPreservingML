{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "c2760c72956b3d3"
  },
  {
   "cell_type": "code",
   "id": "c29d01d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T15:40:06.339221Z",
     "start_time": "2025-11-05T15:40:03.319508Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T15:40:25.276048Z",
     "start_time": "2025-11-05T15:40:06.371547Z"
    }
   },
   "cell_type": "code",
   "id": "81bbf67e",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Trained CNN",
   "id": "ca69fe0bf0214053"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T15:40:26.099656Z",
     "start_time": "2025-11-05T15:40:25.885809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda pic: torch.tensor(np.array(pic), dtype=torch.float32).unsqueeze(0))\n",
    "])\n",
    "\n",
    "# Load training and test datasets\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ],
   "id": "ec44f3165f628cc6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "8f8ff355",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T15:40:26.325836Z",
     "start_time": "2025-11-05T15:40:26.315015Z"
    }
   },
   "source": [
    "# Define a lightweight CNN architecture\n",
    "class LightweightCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LightweightCNN, self).__init__()\n",
    "\n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 128)  # 28x28 -> 14x14 -> 7x7 -> 3x3 after pooling\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        # Flatten and fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T15:40:26.384837Z",
     "start_time": "2025-11-05T15:40:26.378748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.01)  # smaller std for large inputs\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)"
   ],
   "id": "7693a69ca22d4ca5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "fb3f84ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T15:40:26.442746Z",
     "start_time": "2025-11-05T15:40:26.414592Z"
    }
   },
   "source": [
    "# Initialize the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LightweightCNN(num_classes=10).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "print(f\"Model created on device: {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created on device: cpu\n",
      "Total parameters: 98,666\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "fe24be06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T15:41:57.627454Z",
     "start_time": "2025-11-05T15:40:26.472075Z"
    }
   },
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, device, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "            if batch_idx % 200 == 0:\n",
    "                print(f'Epoch {epoch + 1}/{epochs}, Batch {batch_idx}/{len(train_loader)}, '\n",
    "                      f'Loss: {loss.item():.4f}, Accuracy: {100. * correct / total:.2f}%')\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        print(f'Epoch {epoch + 1} completed - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "        print('-' * 50)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "train_model(model, train_loader, criterion, optimizer, device, epochs=3)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/3, Batch 0/938, Loss: 2.3323, Accuracy: 14.06%\n",
      "Epoch 1/3, Batch 200/938, Loss: 0.2656, Accuracy: 81.48%\n",
      "Epoch 1/3, Batch 400/938, Loss: 0.1555, Accuracy: 88.23%\n",
      "Epoch 1/3, Batch 600/938, Loss: 0.1753, Accuracy: 91.06%\n",
      "Epoch 1/3, Batch 800/938, Loss: 0.0596, Accuracy: 92.46%\n",
      "Epoch 1 completed - Loss: 0.2416, Accuracy: 93.14%\n",
      "--------------------------------------------------\n",
      "Epoch 2/3, Batch 0/938, Loss: 0.0793, Accuracy: 96.88%\n",
      "Epoch 2/3, Batch 200/938, Loss: 0.1064, Accuracy: 97.81%\n",
      "Epoch 2/3, Batch 400/938, Loss: 0.0315, Accuracy: 97.78%\n",
      "Epoch 2/3, Batch 600/938, Loss: 0.0648, Accuracy: 97.83%\n",
      "Epoch 2/3, Batch 800/938, Loss: 0.0938, Accuracy: 97.95%\n",
      "Epoch 2 completed - Loss: 0.0698, Accuracy: 97.97%\n",
      "--------------------------------------------------\n",
      "Epoch 3/3, Batch 0/938, Loss: 0.0205, Accuracy: 100.00%\n",
      "Epoch 3/3, Batch 200/938, Loss: 0.1720, Accuracy: 98.41%\n",
      "Epoch 3/3, Batch 400/938, Loss: 0.0065, Accuracy: 98.40%\n",
      "Epoch 3/3, Batch 600/938, Loss: 0.0153, Accuracy: 98.43%\n",
      "Epoch 3/3, Batch 800/938, Loss: 0.0207, Accuracy: 98.42%\n",
      "Epoch 3 completed - Loss: 0.0526, Accuracy: 98.45%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "3ec1ed97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T15:42:00.235682Z",
     "start_time": "2025-11-05T15:41:57.782769Z"
    }
   },
   "source": [
    "# Test the model\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Evaluate the trained model\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_accuracy = test_model(model, test_loader, device)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on test set...\n",
      "Test Loss: 0.0305\n",
      "Test Accuracy: 99.00%\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "d66e75db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T15:42:00.935523Z",
     "start_time": "2025-11-05T15:42:00.264663Z"
    }
   },
   "source": [
    "# Visualize some predictions\n",
    "def visualize_predictions(model, test_loader, device, num_samples=8):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of test data\n",
    "        data_iter = iter(test_loader)\n",
    "        images, labels = next(data_iter)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Get predictions\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        # Move back to CPU for visualization\n",
    "        images = images.cpu()\n",
    "        labels = labels.cpu()\n",
    "        predicted = predicted.cpu()\n",
    "\n",
    "        img = images[0]\n",
    "\n",
    "        img_np = img.squeeze().numpy()  # remove channel dimension\n",
    "\n",
    "        print(\"Pixel values of the first image:\")\n",
    "        print(img_np)\n",
    "\n",
    "        print(f\"Min value: {img_np.min()}, Max value: {img_np.max()}\")\n",
    "\n",
    "        # Create subplot\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "        axes = axes.ravel()\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            axes[i].imshow(images[i].squeeze(), cmap='gray')\n",
    "            axes[i].set_title(f'True: {labels[i].item()}, Pred: {predicted[i].item()}')\n",
    "            axes[i].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Visualize predictions\n",
    "print(\"Visualizing some predictions...\")\n",
    "visualize_predictions(model, test_loader, device)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing some predictions...\n",
      "Pixel values of the first image:\n",
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.  84. 185. 159. 151.  60.  36.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0. 222. 254. 254. 254. 254. 241. 198. 198.\n",
      "  198. 198. 198. 198. 198. 198. 170.  52.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.  67. 114.  72. 114. 163. 227. 254. 225.\n",
      "  254. 254. 254. 250. 229. 254. 254. 140.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  17.  66.  14.\n",
      "   67.  67.  67.  59.  21. 236. 254. 106.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.  83. 253. 209.  18.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.  22. 233. 255.  83.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0. 129. 254. 238.  44.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.  59. 249. 254.  62.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0. 133. 254. 187.   5.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   9. 205. 248.  58.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0. 126. 254. 182.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   75. 251. 240.  57.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  19.\n",
      "  221. 254. 166.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3. 203.\n",
      "  254. 219.  35.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  38. 254.\n",
      "  254.  77.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  31. 224. 254.\n",
      "  115.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 133. 254. 254.\n",
      "   52.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  61. 242. 254. 254.\n",
      "   52.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 121. 254. 254. 219.\n",
      "   40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 121. 254. 207.  18.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n",
      "Min value: 0.0, Max value: 255.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 8 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "a670e23b",
   "metadata": {},
   "source": "## IPFE-enhanced CNN"
  },
  {
   "cell_type": "code",
   "id": "e7a0076c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T15:42:28.036858Z",
     "start_time": "2025-11-05T15:42:27.989712Z"
    }
   },
   "source": [
    "# import ipfe functions\n",
    "from altered_ipfe import IPFE"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### current try",
   "id": "a0e9809d3ef7052c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In the First layer we applied 16 filters of size 3x3, with input channel 1 (grayscale), so the total number of parameters is 16 * 3 * 3 * 1 = 144.\n",
    "\n",
    "So With that each y is one filter flattened to a vector of length 9.\n",
    "For an input x of size 28x28, flattened to a vector of length 784, we can compute the inner product <x, y> for each filter y.\n",
    "\n",
    "Option 1 encrypt the entire input x of length 784, and padd the y to a length of 784 with zeros. -> This will be inefficient as the IPFE scheme will have to handle large vectors.\n",
    "\n",
    "Option 2 encrypt patches of x corresponding to the filter size (3x3 = 9 elements), and compute the inner product for each patch with the filter y. This requires sliding the filter over the input image and encrypting each patch separately.\n",
    "\n",
    "1. Step: Create patches of size 3x3 from the input image (28x28) -> This will create 28x28 patches (with padding). => 784 patches\n",
    "2. Step: Encrypt each patch separately.\n",
    "3. Step: Create 16 query vectors y (one for each filter), each of size 9 (3x3 flattened). => Create a Key for each vector\n",
    "4. Step: decrypt each inner product result to get the convolution output."
   ],
   "id": "e412789862c18ee8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T16:50:09.689379Z",
     "start_time": "2025-11-05T16:50:09.672508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class IPFECNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, prime=1000000007):\n",
    "        super(IPFECNN, self).__init__()\n",
    "        self.prime = prime\n",
    "        self.ipfe = IPFE(prime)\n",
    "        self.encryption_length = 9 # 3x3 filter size flattened\n",
    "\n",
    "        self.ipfe.setup(self.encryption_length)\n",
    "        print(\"IPFE setup done, with length:\", self.encryption_length)\n",
    "\n",
    "        # First convolutional block - this will be used with IPFE\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "        #copy weights from the trained model\n",
    "        self.load_state_dict(model.state_dict())\n",
    "        print(\"weights copied from trained model\")\n",
    "\n",
    "        self.weights = self.conv1.weight.data\n",
    "        self.y_array = torch.round(self.weights.view(self.weights.size(0), -1).squeeze(1).view(self.weights.size(0), -1) * 10000).long().tolist()\n",
    "        print(\"weights converted to y vectors\")\n",
    "        self.biases = self.conv1.bias\n",
    "        print(\"biases saved\")\n",
    "        self.sk_y_array = [self.ipfe.key_derive(y) for y in self.y_array]\n",
    "        print(\"sk_ys created\")\n",
    "\n",
    "    def encrypt_data(self, test_set):\n",
    "        unfold = nn.Unfold(kernel_size=3, stride=1, padding=1)\n",
    "        patches = unfold(test_set)\n",
    "        B, patch_size, num_patches = patches.shape\n",
    "\n",
    "        encrypted_patches = []\n",
    "\n",
    "        for b in range(B):\n",
    "            patches_b = patches[b].T  # (H*W, patch_size)\n",
    "            encrypted_image = []\n",
    "            for p in range(num_patches):\n",
    "                patch = patches_b[p]\n",
    "                patch_int = [(int(val.item()) % (self.prime - 1)) for val in patch]\n",
    "                encrypted = self.ipfe.encrypt(patch_int)  # could be tuple\n",
    "                encrypted_image.append(encrypted)\n",
    "            encrypted_patches.append(encrypted_image)\n",
    "\n",
    "        return encrypted_patches\n",
    "\n",
    "\n",
    "    def first_conv_forward(self, x, H, W):\n",
    "        num_patches = len(x)\n",
    "        num_kernels = len(self.sk_y_array)\n",
    "        device = next(self.parameters()).device\n",
    "\n",
    "        feature_maps_batch = []\n",
    "\n",
    "        decrypted_maps = torch.zeros(num_kernels, num_patches, device=device)\n",
    "\n",
    "        for k in range(num_kernels):\n",
    "            for p in range(num_patches):\n",
    "                decrypted_scaled = self.ipfe.decrypt(\n",
    "                    x[p],\n",
    "                    self.sk_y_array[k],\n",
    "                    self.y_array[k],\n",
    "                )\n",
    "                decrypted = (decrypted_scaled / 10000) + self.biases[k].item()\n",
    "                decrypted_maps[k, p] = decrypted\n",
    "\n",
    "        return torch.stack([decrypted_maps.view(num_kernels, H, W)], dim=0)\n",
    "\n",
    "\n",
    "    def forward(self, x, H, W, encrypted=False):\n",
    "        if encrypted:\n",
    "            outputs = []\n",
    "            for sample in x:  # x = [ [patches_img1], [patches_img2], ... ]\n",
    "                feat = self.first_conv_forward(sample, H, W)\n",
    "                feat = self.pool1(F.relu(self.bn1(feat)))\n",
    "                feat = self.pool2(F.relu(self.bn2(self.conv2(feat))))\n",
    "                feat = self.pool3(F.relu(self.bn3(self.conv3(feat))))\n",
    "                feat = feat.view(feat.size(0), -1)\n",
    "                feat = F.relu(self.fc1(feat))\n",
    "                feat = self.dropout(feat)\n",
    "                feat = self.fc2(feat)\n",
    "                outputs.append(feat)\n",
    "            return torch.cat(outputs, dim=0)\n",
    "        else:\n",
    "            x = self.conv1(x)\n",
    "            x = self.pool1(F.relu(self.bn1(x)))\n",
    "            x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "            x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n"
   ],
   "id": "5b0995bba0a5f9bb",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T16:50:12.049467Z",
     "start_time": "2025-11-05T16:50:12.034771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize IPFE-enhanced CNN\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ipfe_model = IPFECNN(num_classes=10, prime=1000000007).to(device)\n",
    "\n",
    "print(f\"IPFE-CNN model created on device: {device}\")"
   ],
   "id": "48f5b434a96cfcb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPFE setup done, with length: 9\n",
      "weights copied from trained model\n",
      "weights converted to y vectors\n",
      "biases saved\n",
      "sk_ys created\n",
      "IPFE-CNN model created on device: cpu\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T16:50:21.495515Z",
     "start_time": "2025-11-05T16:50:21.490245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encrypt_test_data(model, test_loader, device, num_samples=5):\n",
    "    \"\"\"Encrypt a batch of test data\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Get a batch of test data\n",
    "        data_iter = iter(test_loader)\n",
    "        images, labels = next(data_iter)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Encrypt only a subset\n",
    "        images_subset = images[:num_samples]\n",
    "        labels_subset = labels[:num_samples]\n",
    "\n",
    "        # Encrypt the data\n",
    "        encrypted_data = model.encrypt_data(images_subset)\n",
    "        print(f\"Encrypted {num_samples} samples.\")\n",
    "\n",
    "        H, W = images.size(2), images.size(3)\n",
    "\n",
    "    return encrypted_data, labels_subset, H, W"
   ],
   "id": "f7b0413ef3a19de4",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T16:50:23.308467Z",
     "start_time": "2025-11-05T16:50:23.180416Z"
    }
   },
   "cell_type": "code",
   "source": "encrypted_data, labels, H, W = encrypt_test_data(ipfe_model, test_loader, device, num_samples=2)",
   "id": "743adafe19e1c144",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encrypted 2 samples.\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T16:50:24.242859Z",
     "start_time": "2025-11-05T16:50:24.234254Z"
    }
   },
   "cell_type": "code",
   "source": "len(encrypted_data)",
   "id": "f6c8d3033ff4b191",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T16:59:02.273858Z",
     "start_time": "2025-11-05T16:59:02.267931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test IPFE functionality with a sample\n",
    "def test_ipfe_cnn(model, encrypted_data, labels, H, W, device):\n",
    "    \"\"\"Test the IPFE-CNN with a sample query vector\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"Testing IPFE-CNN forward pass on encrypted data...\")\n",
    "        print(f\"Labels of test samples: {labels.cpu().numpy()}\")\n",
    "\n",
    "        try:\n",
    "            outputs = model.forward(encrypted_data, encrypted=True, H=H, W=W)\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            print(f\"Predictions on encrypted data: {predicted.cpu().numpy()}\")\n",
    "\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            total = labels.size(0)\n",
    "            print(f\"Accuracy on encrypted samples: {100 * correct / total:.2f}% ({correct}/{total})\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Encrypted IPFE forward pass failed: {e}\")\n"
   ],
   "id": "d06bc5ba89e5cfa6",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T17:02:38.784073Z",
     "start_time": "2025-11-05T16:59:06.847567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Testing IPFE-CNN functionality...\")\n",
    "test_ipfe_cnn(ipfe_model, encrypted_data, labels, H, W, device)\n"
   ],
   "id": "7c27e8d3d7435993",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing IPFE-CNN functionality...\n",
      "Testing IPFE-CNN forward pass on encrypted data...\n",
      "Labels of test samples: [7 2]\n",
      "Predictions on encrypted data: [7 2]\n",
      "Accuracy on encrypted samples: 100.00% (2/2)\n"
     ]
    }
   ],
   "execution_count": 75
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
